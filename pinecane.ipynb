{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cohere\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import Cohere\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load environment variables (for Cohere API key)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize Cohere client\n",
    "co = cohere.Client(\"Lt7NBVBllT6ZU1FwA3bUq1NmTYASnP14fLIInOct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: PDF Reader function to load and process the PDF\n",
    "def read_pdf(file_path):\n",
    "    file_loader = PyPDFLoader(file_path)\n",
    "    documents = file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pages in the document: 9\n"
     ]
    }
   ],
   "source": [
    "# Example: Load a PDF document\n",
    "doc = read_pdf(r'D:\\ChatBot_LLM3\\sigma.pdf')  # Modify with your PDF file path\n",
    "print(f\"Total Pages in the document: {len(doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Chunk the document using a Recursive Text Splitter\n",
    "def chunk_data(docs, chunk_size=800, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs_chunked = text_splitter.split_documents(docs)\n",
    "    return docs_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks Created: 31\n"
     ]
    }
   ],
   "source": [
    "# Chunk the PDF document into smaller parts\n",
    "documents = chunk_data(docs=doc)\n",
    "print(f\"Total Chunks Created: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings \n",
    "# Step 5: Cohere Embedding Function\n",
    "class CohereEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        response = co.embed(texts=texts)\n",
    "        return response.embeddings\n",
    "    \n",
    "    def embed_query(self, text: str) -> list[float]:\n",
    "        response = co.embed(texts=[text])\n",
    "        return response.embeddings[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Store embeddings in FAISS\n",
    "def store_faiss_embeddings(embeddings, documents):\n",
    "    dimension = len(embeddings[0])\n",
    "    index = faiss.IndexFlatL2(dimension)  # Create FAISS index with L2 distance\n",
    "    index.add(np.array(embeddings))  # Add embeddings to FAISS index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Cohere embeddings for the document chunks\n",
    "texts = [doc.page_content for doc in documents]\n",
    "cohere_embedder = CohereEmbeddings()\n",
    "embeddings = cohere_embedder.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Index has been created and saved.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "# Store embeddings in FAISS\n",
    "faiss_index = store_faiss_embeddings(embeddings, documents)\n",
    "\n",
    "# Optionally, save the FAISS index to disk\n",
    "faiss.write_index(faiss_index, \"faiss_index.idx\")\n",
    "print(\"FAISS Index has been created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Search FAISS for relevant documents based on query\n",
    "def search_faiss_index(query):\n",
    "    # Embed the query using Cohere\n",
    "    query_embedding = cohere_embedder.embed_documents([query])\n",
    "    query_vector = np.array(query_embedding)\n",
    "    \n",
    "    # Search the FAISS index for the top 5 similar chunks\n",
    "    D, I = faiss_index.search(query_vector, k=5)\n",
    "    return I  # Return indices of matching documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Chunk Indices: [[23  3 10 15  4]]\n"
     ]
    }
   ],
   "source": [
    "# Example query for retrieving matching chunks\n",
    "query = \"give me a information about Akshay Residency\"\n",
    "result_indices = search_faiss_index(query)\n",
    "print(f\"Matching Chunk Indices: {result_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12364\\2935191372.py:5: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 1.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import Cohere`.\n",
      "  llm = Cohere(cohere_api_key='Lt7NBVBllT6ZU1FwA3bUq1NmTYASnP14fLIInOct')  # Replace with your actual API key\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12364\\2935191372.py:8: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/v0.2/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag\n",
      "  qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import Cohere\n",
    "\n",
    "# Initialize Cohere LLM with the correct API key parameter\n",
    "llm = Cohere(cohere_api_key='Lt7NBVBllT6ZU1FwA3bUq1NmTYASnP14fLIInOct')  # Replace with your actual API key\n",
    "\n",
    "# Load the QA chain\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the matching documents based on the retrieved indices from FAISS\n",
    "matching_documents = [documents[i] for i in result_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12364\\1180479702.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  answer = qa_chain.run(input_documents=matching_documents, question=query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Here's the information I have on file for Akshay Residency: \n",
      "\n",
      "1. Location: Wakad, Pune\n",
      "2. Developer: Akshay Developers\n",
      "3. Date of Completion: November 2017\n",
      "4. Status: Completed\n",
      "5. Connectivity: Close to Wakad Road, minutes from Mumbai-Pune Expressway\n",
      "6. Amenities: \n",
      "- 24/7 Security\n",
      "- Kids Play Area\n",
      "- Parking\n",
      "- Garden & Landscaping\n",
      "\n",
      "I hope this information is helpful. Please let me know if there's anything else I can assist you with. \n"
     ]
    }
   ],
   "source": [
    "answer = qa_chain.run(input_documents=matching_documents, question=query)\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
